{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试\n",
    "\n",
    "先对基础模型进行正确性测试作为基线，在本地基于ragas进行测试\n",
    "\n",
    "https://docs.ragas.io/en/latest/concepts/metrics/index.html\n",
    "\n",
    "测试指标：\n",
    "\n",
    "1. Answer semantic similarity [答案语义相似度](https://docs.ragas.io/en/latest/concepts/metrics/semantic_similarity.html)\n",
    "2. Answer Correctness [答案正确性](https://docs.ragas.io/en/latest/concepts/metrics/answer_correctness.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 调用mannager进行预测并且评估\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "for i in range(1,7):\n",
    "    if i != 1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    manager = Manager(model='rag',\n",
    "                    filepath=f\"eval_reasult/{i}/new_eval\",\n",
    "                    rag_fusion = True,\n",
    "                    summary_llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.9))\n",
    "    manager.restart_predict(dataloader)\n",
    "    #predictor = PredictorFactory.get_predictor(model_type='rag',\n",
    "    #                summary_llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.9))\n",
    "    #manager.run_predict(dataloader)\n",
    "    manager.run_evaluate()\n",
    "    manager.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4')\n",
    "llm.invoke(\"sss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "\"\"\"\n",
    "for i in range(1,7):\n",
    "    dataloader = DataLoader(f\"_data\\QA\\\\{i}\\good_{i}.json\")\n",
    "    dataloader.data = dataloader.load_extract_data(f\"_data\\QA\\\\{i}\\good_{i}.json\")\n",
    "    with open(f\"_data\\\\testqa\\\\testdata_{i}.json\", 'w', encoding='utf-8') as file:\n",
    "        json.dump(dataloader.data , file, indent=4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 调用mannager进行预测并且评估\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i !=1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa2\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    manager = Manager(model='rag',\n",
    "                    filepath=f\"eval_reasult2/{i}/rag_fusion_new_eval\",\n",
    "                    rag_fusion = True,\n",
    "                    summary_llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.9))\n",
    "\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验0 -- 基线情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/ablat1_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = True,\n",
    "                    step_back = True,\n",
    "                    r1 = True,\n",
    "                    r2 = True,\n",
    "                    IE=True,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验1 --去除RAG-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <5:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/ablat2_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = False,\n",
    "                    step_back = True,\n",
    "                    r1 = True,\n",
    "                    r2 = True,\n",
    "                    IE=True,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验2 去除step_back\n",
    "\n",
    "new_ablat3_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-56a1a635-664f-4add-81fb-ed43ba8577c4-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke('sss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donkey\\.conda\\envs\\EDT\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True False\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/new_ablat3_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = True,\n",
    "                    step_back = False,\n",
    "                    r1 = True,\n",
    "                    r2 = True,\n",
    "                    IE=True,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验3 -- 去除r1\n",
    "\n",
    "new_ablat4_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "True True\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/new_ablat4_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = False, # rag_fusion在r1内\n",
    "                    step_back = True,\n",
    "                    r1 = False,\n",
    "                    r2 = True,\n",
    "                    IE=True,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验4 去除r2\n",
    "\n",
    "new_ablat5_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donkey\\.conda\\envs\\EDT\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <1:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/new_ablat5_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = True,\n",
    "                    step_back = True,\n",
    "                    r1 = True,\n",
    "                    r2 = False,\n",
    "                    IE=True,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消融实验5   去除IE\n",
    "\n",
    "new_ablat6_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"RAG\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\"\"\"\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Manager,Record\n",
    "from PK_LLM_endfront.evaluation.llms import PredictorFactory\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\donkey\\.conda\\envs\\EDT\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length context = 767\n",
      "1\n",
      "length context = 1786\n",
      "2\n",
      "length context = 1014\n",
      "3\n",
      "length context = 1130\n",
      "4\n",
      "length context = 638\n",
      "5\n",
      "length context = 3192\n",
      "6\n",
      "length context = 1448\n",
      "7\n",
      "length context = 1535\n",
      "8\n",
      "length context = 186\n",
      "9\n",
      "length context = 1013\n",
      "10\n",
      "length context = 1112\n",
      "11\n",
      "length context = 1683\n",
      "12\n",
      "length context = 1527\n",
      "13\n",
      "length context = 1374\n",
      "14\n",
      "length context = 1133\n",
      "15\n",
      "length context = 801\n",
      "16\n",
      "length context = 1083\n",
      "17\n",
      "length context = 1797\n",
      "18\n",
      "length context = 727\n",
      "19\n",
      "length context = 1623\n",
      "20\n",
      "length context = 1510\n",
      "21\n",
      "length context = 1873\n",
      "22\n",
      "length context = 1522\n",
      "23\n",
      "length context = 1636\n",
      "24\n",
      "length context = 981\n",
      "25\n",
      "length context = 3446\n",
      "26\n",
      "length context = 1235\n",
      "27\n",
      "length context = 1282\n",
      "28\n",
      "length context = 1402\n",
      "29\n",
      "length context = 2671\n",
      "30\n",
      "length context = 1698\n",
      "31\n",
      "length context = 1536\n",
      "32\n",
      "length context = 2014\n",
      "33\n",
      "length context = 1672\n",
      "34\n",
      "length context = 1771\n",
      "35\n",
      "length context = 1509\n",
      "36\n",
      "length context = 3730\n",
      "37\n",
      "length context = 3594\n",
      "38\n",
      "length context = 1540\n",
      "39\n",
      "length context = 3363\n",
      "40\n",
      "length context = 1149\n",
      "41\n",
      "length context = 1922\n",
      "42\n",
      "length context = 1463\n",
      "43\n",
      "length context = 1018\n",
      "44\n",
      "length context = 1676\n",
      "45\n",
      "length context = 2482\n",
      "46\n",
      "length context = 728\n",
      "47\n",
      "length context = 1430\n",
      "48\n",
      "length context = 902\n",
      "49\n",
      "length context = 1761\n",
      "0\n",
      "length context = 946\n",
      "1\n",
      "length context = 3242\n",
      "2\n",
      "length context = 1312\n",
      "3\n",
      "length context = 1456\n",
      "4\n",
      "length context = 1344\n",
      "5\n",
      "length context = 4879\n",
      "6\n",
      "length context = 3242\n",
      "7\n",
      "length context = 1749\n",
      "8\n",
      "length context = 3923\n",
      "9\n",
      "length context = 1469\n",
      "10\n",
      "length context = 1899\n",
      "11\n",
      "length context = 3636\n",
      "12\n",
      "length context = 1228\n",
      "13\n",
      "length context = 784\n",
      "14\n",
      "length context = 3349\n",
      "15\n",
      "length context = 1044\n",
      "16\n",
      "length context = 2592\n",
      "17\n",
      "length context = 2774\n",
      "18\n",
      "length context = 1492\n",
      "19\n",
      "length context = 1369\n",
      "20\n",
      "length context = 2583\n",
      "21\n",
      "length context = 2224\n",
      "22\n",
      "length context = 2454\n",
      "23\n",
      "length context = 815\n",
      "24\n",
      "length context = 3457\n",
      "25\n",
      "length context = 1386\n",
      "26\n",
      "length context = 1572\n",
      "27\n",
      "length context = 1287\n",
      "28\n",
      "length context = 1794\n",
      "29\n",
      "length context = 4032\n",
      "30\n",
      "length context = 2211\n",
      "31\n",
      "length context = 1295\n",
      "32\n",
      "length context = 1645\n",
      "33\n",
      "length context = 3609\n",
      "34\n",
      "length context = 2085\n",
      "35\n",
      "length context = 3948\n",
      "36\n",
      "length context = 1642\n",
      "37\n",
      "length context = 3486\n",
      "38\n",
      "length context = 2210\n",
      "39\n",
      "length context = 2086\n",
      "40\n",
      "length context = 2039\n",
      "41\n",
      "length context = 3173\n",
      "42\n",
      "length context = 1974\n",
      "43\n",
      "length context = 2683\n",
      "44\n",
      "length context = 1265\n",
      "45\n",
      "length context = 1852\n",
      "46\n",
      "length context = 2999\n",
      "47\n",
      "length context = 2669\n",
      "48\n",
      "length context = 3539\n",
      "49\n",
      "length context = 1543\n",
      "0\n",
      "length context = 1339\n",
      "1\n",
      "length context = 1872\n",
      "2\n",
      "length context = 1133\n",
      "3\n",
      "length context = 1101\n",
      "4\n",
      "length context = 1898\n",
      "5\n",
      "length context = 1434\n",
      "6\n",
      "length context = 1757\n",
      "7\n",
      "length context = 1757\n",
      "8\n",
      "length context = 1972\n",
      "9\n",
      "length context = 1303\n",
      "10\n",
      "length context = 1400\n",
      "11\n",
      "length context = 2779\n",
      "12\n",
      "length context = 1448\n",
      "13\n",
      "length context = 2306\n",
      "14\n",
      "length context = 1853\n",
      "15\n",
      "length context = 1861\n",
      "16\n",
      "length context = 1471\n",
      "17\n",
      "length context = 2174\n",
      "18\n",
      "length context = 1665\n",
      "19\n",
      "length context = 656\n",
      "20\n",
      "length context = 3575\n",
      "21\n",
      "length context = 1602\n",
      "22\n",
      "length context = 1218\n",
      "23\n",
      "length context = 2504\n",
      "24\n",
      "length context = 2405\n",
      "25\n",
      "length context = 2154\n",
      "26\n",
      "length context = 2958\n",
      "27\n",
      "length context = 1861\n",
      "28\n",
      "length context = 2210\n",
      "29\n",
      "length context = 1408\n",
      "30\n",
      "length context = 1144\n",
      "31\n",
      "length context = 584\n",
      "32\n",
      "length context = 2527\n",
      "33\n",
      "length context = 3181\n",
      "34\n",
      "length context = 1421\n",
      "35\n",
      "length context = 1187\n",
      "36\n",
      "length context = 2229\n",
      "37\n",
      "length context = 1575\n",
      "38\n",
      "length context = 1304\n",
      "39\n",
      "length context = 1629\n",
      "40\n",
      "length context = 1842\n",
      "41\n",
      "length context = 1737\n",
      "42\n",
      "length context = 1083\n",
      "43\n",
      "length context = 1406\n",
      "44\n",
      "length context = 1244\n",
      "45\n",
      "length context = 1661\n",
      "46\n",
      "length context = 1487\n",
      "47\n",
      "length context = 2816\n",
      "48\n",
      "length context = 1786\n",
      "49\n",
      "length context = 1295\n",
      "0\n",
      "length context = 1183\n",
      "1\n",
      "length context = 2281\n",
      "2\n",
      "length context = 1757\n",
      "3\n",
      "length context = 3003\n",
      "4\n",
      "length context = 1153\n",
      "5\n",
      "length context = 1083\n",
      "6\n",
      "length context = 2922\n",
      "7\n",
      "length context = 1356\n",
      "8\n",
      "length context = 2552\n",
      "9\n",
      "length context = 1248\n",
      "10\n",
      "length context = 1607\n",
      "11\n",
      "length context = 1718\n",
      "12\n",
      "length context = 1133\n",
      "13\n",
      "length context = 2546\n",
      "14\n",
      "length context = 1325\n",
      "15\n",
      "length context = 1519\n",
      "16\n",
      "length context = 1854\n",
      "17\n",
      "length context = 3110\n",
      "18\n",
      "length context = 1793\n",
      "19\n",
      "length context = 1812\n",
      "20\n",
      "length context = 760\n",
      "21\n",
      "length context = 1283\n",
      "22\n",
      "length context = 1146\n",
      "23\n",
      "length context = 1559\n",
      "24\n",
      "length context = 1362\n",
      "25\n",
      "length context = 1131\n",
      "26\n",
      "length context = 1529\n",
      "27\n",
      "length context = 2756\n",
      "28\n",
      "length context = 1374\n",
      "29\n",
      "length context = 1002\n",
      "30\n",
      "length context = 847\n",
      "31\n",
      "length context = 1271\n",
      "32\n",
      "length context = 1105\n",
      "33\n",
      "length context = 1776\n",
      "34\n",
      "length context = 3668\n",
      "35\n",
      "length context = 1228\n",
      "36\n",
      "length context = 1129\n",
      "37\n",
      "length context = 1277\n",
      "38\n",
      "length context = 1242\n",
      "39\n",
      "length context = 1848\n",
      "40\n",
      "length context = 834\n",
      "41\n",
      "length context = 2509\n",
      "42\n",
      "length context = 933\n",
      "43\n",
      "length context = 1604\n",
      "44\n",
      "length context = 1058\n",
      "45\n",
      "length context = 1150\n",
      "46\n",
      "length context = 1605\n",
      "47\n",
      "length context = 939\n",
      "48\n",
      "length context = 986\n",
      "49\n",
      "length context = 1118\n"
     ]
    }
   ],
   "source": [
    "# 对rag进行消融实验\n",
    "# 消融顺序:原来的样子,rag-fusion,step-back,r1,[r2,IE]\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "for i in range(1,7):\n",
    "    if i <3:\n",
    "        continue\n",
    "    dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{i}.json\")\n",
    "    dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #dataloader.data = dataloader.load_json(dataloader.filepath)\n",
    "    #manager = Manager(model='glm-4',filepath=f\"eval_reasult/{i}/eval\")\n",
    "    \n",
    "    manager = Manager(model='rag_context',\n",
    "                    filepath=f\"eval_reasult2/{i}/new_ablat6_eval\",\n",
    "                    kb_id = i,\n",
    "                    rag_fusion = True,\n",
    "                    step_back = False,\n",
    "                    r1 = True,\n",
    "                    r2 = True,\n",
    "                    IE=False,\n",
    "                    k1=1,\n",
    "                    k2=2,\n",
    "                    )\n",
    "    manager.record_lis = []\n",
    "    manager.run_predict(dataloader)\n",
    "    #manager.run_evaluate()\n",
    "    manager.save()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PK_LLM_endfront.evaluation 使用文档\n",
    "``` python\n",
    "# manager类预测原理\n",
    "import os\n",
    "os.chdir('E:\\学习\\python\\py_codbase\\PK_LLM')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "from PK_LLM_endfront.evaluation.eva_funcs import DataLoader,Evaluator,Record\n",
    "from PK_LLM_endfront.evaluation.llms import predictor,PredictorFactory,GPTPredictor\n",
    "\n",
    "dataloader = DataLoader(f\"_data\\\\testqa\\\\testdata_{1}.json\")\n",
    "e = Evaluator()\n",
    "# 1. 获取Record类\n",
    "r = next(dataloader.get_data()) # record demo\n",
    "print(r)\n",
    "# 2. make Predictor instance\n",
    "# 2.1 use PredictorFactory \n",
    "p = PredictorFactory().get_predictor(model_type='gpt-3.5-turbo',\n",
    "                                    temperature = 0.9)\n",
    "print(type(p))\n",
    "# 2.2 creat dirctly\n",
    "p = GPTPredictor()\n",
    "p.run(\"我应该如何准备和女朋友的纪念日\")\n",
    "\n",
    "# 3.Put Predictor into Record to execute example\n",
    "r.add_prediction(p)\n",
    "print(r)\n",
    "\n",
    "# 4. To perform batch testing, integrate the current record into the evaluator.\n",
    "e.add_Record(r)\n",
    "e.evaluate()\n",
    "\n",
    "# or Evaluator provide a method to eun eval easily\n",
    "# e.run_eval(dataloader=dataloader,model=\"gpt-3.5-turbo\",time_=0.2)\n",
    "\n",
    "# 5. save result \n",
    "e.save(f\"_temp/eval_{p.prefix}.csv\")\n",
    "e.df\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
